{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es importar la clase GenerativeGrammar, que es la que nos permite trabajar con gramáticas independientes del contexto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammar import GenerativeGrammar\n",
    "from production_rule import ProductionRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y escritura de gramáticas en ficheros\n",
    "\n",
    "La gramática la podemos crear leyéndola desde un fichero. Dicho fichero tendrá la siguiente estructura.\n",
    "\n",
    "- La primera línea contiene las variables de la gramática. Tal línea siempre empezará por \"V = \" para indicar que se está especificando el cto de variables. El conjunto de variables irá comprendido entre llaves. Las variables siempre empezarán por letra mayúscula. Cuando una variable tiene más de un símbolo empezará por '<' y terminará por '>', clarificando así que es una variable compuesta por más de un símbolo. Esto sirve, por ejemplo, para no confundir '<A1>' con el símbolo A seguido de un 1. Siempre la primera variable será la variable inicial. \n",
    "    \n",
    "- La segunda línea contiene los símbolos terminales de la gramática. Para indicar que se está especificando el conjunto de símbolos terminales, dicha línea empezará por \"T = \". El conjunto de símbolos terminales estará delimitado por llaves y los símbolos terminales irán separados por comas. \n",
    "    \n",
    "- A partir de la cuarta línea (tras una línea en blanco) irán las producciones. Habrá una línea por cada variable que aparezca en la parte de la izquierda de las producciones. Dicha línea siempre empezará por esa variable seguido de \" -> \". Después aparecerán las partes derechas de cada una de esas producciones separadas por \"|\". \n",
    "    \n",
    "Una vez que tenemos creado este fichero, debemos indicar la ruta relativa donde se encuentra. Después debemos de llamar al método de clase readGrammar pasándo como parámetro dicha ruta para tener generada la gramática. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_read = \"grammar_proof.txt\"\n",
    "generated_grammar = GenerativeGrammar.readGrammar(path_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, dado un objeto de la clase GenerativeGrammar, podemos escribir la gramática en un fichero espeficiando la \n",
    "ruta de dicho fichero. Para ello, hemos emplear el método writeGrammar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = \"grammar_written.txt\"\n",
    "generated_grammar.writeGrammar(path_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivación de palabras con una gramática independiente del contexto\n",
    "\n",
    "El método applyProductionRule recibe como parámetros una palabra, el comienzo y el fin de una regla de producción y la regla de producción a aplicar a una palabra y devuelve la palabra resultante de aplicar esa regla en las posiciones indicadas. \n",
    "\n",
    "Mostramos debajo cómo obtener la palabra aabbaa mediante derivaciones sucesivas en la gramática anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aAS\n",
      "aSbAS\n",
      "aabAS\n",
      "aabbaS\n",
      "aabbaa\n"
     ]
    }
   ],
   "source": [
    "initial_word = generated_grammar.start_symbol\n",
    "first_rule = generated_grammar.production_rules[0]\n",
    "\n",
    "second_word = generated_grammar.applyProductionRule(initial_word,0,0,first_rule)\n",
    "print(second_word)\n",
    "\n",
    "second_rule = generated_grammar.production_rules[2]\n",
    "third_word = generated_grammar.applyProductionRule(second_word,1,1,second_rule)\n",
    "print(third_word)\n",
    "\n",
    "third_rule = generated_grammar.production_rules[1]\n",
    "fourth_word = generated_grammar.applyProductionRule(third_word,1,1,third_rule)\n",
    "print(fourth_word)\n",
    "\n",
    "fourth_rule = generated_grammar.production_rules[4]\n",
    "fifth_word = generated_grammar.applyProductionRule(fourth_word,3,3,fourth_rule)\n",
    "print(fifth_word)\n",
    "\n",
    "final_word = generated_grammar.applyProductionRule(fifth_word,5,5,third_rule)\n",
    "print(final_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramáticas lineales\n",
    "\n",
    "Una gramática independiente del contexto es lineal por la derecha (izquierda) si todas las producciones son de la forma $A \\rightarrow uB$ ($A \\rightarrow Bu$), donde u es un símbolo terminal y B es una variable. Los métodos linearRight y linearLeft nos permiten comprobar si una gramática independiente del contexto es lineal por la derecha o por la izquierda, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineal_right = generated_grammar.linearRight()\n",
    "lineal_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineal_left = generated_grammar.linearLeft()\n",
    "lineal_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminación de símbolos y producciones inútiles\n",
    "\n",
    "Lo primero que se debe de hacer cuando se tiene una gramática independiente del contexto es eliminar símbolos y producciones inútiles, es decir, símbolos y producciones que nunca se usan en la derivación de una palabra. El algoritmo para eliminar símbolos y producciones inútiles consta de dos pasos:\n",
    "\n",
    "1. Eliminar las variables desde las que no se puede alcanzar una cadena de símbolos terminales, así como las producciones donde aparezan estas variables. \n",
    "\n",
    "2. Eliminar las variables y símbolos terminales que no son alcanzables desde el símbolo inicial, así como las producciones donde aparezcan estas variables y símbolos. \n",
    "\n",
    "Los símbolos y producciones nulas de la gramática pueden eliminarse con el método deleteUselessSymbolsProductions. A continuación mostramos un ejemplo donde leemos una gramática, eliminamos los símbolos y producciones inútiles y volvemos a escribir la gramática con dichos símbolos y producciones eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the variables that cannot be replaced by terminal symbols\n",
      "Deleting the productions with symbol X\n",
      "Deleting the symbol X\n",
      "Deleting the productions with symbol Y\n",
      "Deleting the symbol Y\n",
      "Deleting the productions with symbol Z\n",
      "Deleting the symbol Z\n",
      "Deleting the variables and symbols not reachable from the initial symbol\n",
      "Deleting the productions with the variable B\n",
      "Deleting the variable B\n",
      "Deleting the productions with the variable D\n",
      "Deleting the variable D\n",
      "Deleting the productions with the variable U\n",
      "Deleting the variable U\n",
      "Deleting the productions with the variable W\n",
      "Deleting the variable W\n",
      "Deleting the terminal symbol a\n",
      "Deleting the terminal symbol b\n",
      "Deleting the terminal symbol c\n",
      "Deleting the terminal symbol d\n",
      "Deleting the terminal symbol f\n",
      "Deleting the terminal symbol h\n",
      "Deleting the terminal symbol j\n",
      "Deleting the terminal symbol k\n",
      "Deleting the terminal symbol m\n",
      "Deleting the terminal symbol n\n"
     ]
    }
   ],
   "source": [
    "path_useless = \"grammar_useless.txt\"\n",
    "grammar_useless = GenerativeGrammar.readGrammar(path_useless)\n",
    "grammar_useless.deleteUselessSymbolsProductions(True)\n",
    "\n",
    "path_write_useless = \"grammar_written_without_useless.txt\"\n",
    "grammar_useless.writeGrammar(path_write_useless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formas normales de la Gramática\n",
    "\n",
    "Para poder pasar la gramática a formas normales debemos de eliminar las producciones nulas y unitarias. El método deleteNullProductions nos permite eliminar las producciones nulas de la gramática. Las producciones unitarias se eliminan con el método deleteUnitaryProductions.\n",
    "\n",
    "A continuación mostramos un ejemplo donde se lee una gramática de fichero, se eliminan las producciones nulas y se escribe la gramática en otro fichero con las producciones nulas eliminadas. Lo mismo con las producciones unitarias. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of nullable variables \n",
      "['A', 'B', 'C', 'S']\n",
      "Removing the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "[]\n",
      "\n",
      "Removing the production \n",
      "Left part: \n",
      "B\n",
      "Right part: \n",
      "[]\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['B', 'b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['A', 'b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['B', 'C']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['A', 'C']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['C']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['A', 'B']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['B']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['A']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['a']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "B\n",
      "Right part: \n",
      "['b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "C\n",
      "Right part: \n",
      "['a', 'b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "C\n",
      "Right part: \n",
      "['B']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "C\n",
      "Right part: \n",
      "['A']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_null_productions = \"grammar_null_productions.txt\"\n",
    "grammar_null_productions = GenerativeGrammar.readGrammar(path_null_productions)\n",
    "grammar_null_productions.deleteNullProductions(True)\n",
    "\n",
    "path_write_null = \"grammar_written_without_null.txt\"\n",
    "grammar_null_productions.writeGrammar(path_write_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of derivable pairs \n",
      "[('S', 'A'), ('A', 'B'), ('S', 'B')]\n",
      "Deleting the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['A']\n",
      "\n",
      "Deleting the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['B']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['a', 'A', 'b']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['c', 'd']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['c', 'c', 'B', 'S']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['d', 'c']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['c', 'c', 'B', 'S']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "S\n",
      "Right part: \n",
      "['d', 'c']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_unitary_productions = \"grammar_unitary_productions.txt\"\n",
    "grammar_unitary_productions = GenerativeGrammar.readGrammar(path_unitary_productions)\n",
    "grammar_unitary_productions.deleteUnitaryProductions(True)\n",
    "\n",
    "path_write_unitary = \"grammar_written_without_unitary.txt\"\n",
    "grammar_unitary_productions.writeGrammar(path_write_unitary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma Normal de Chomsky\n",
    "\n",
    "Una vez eliminadas las producciones nulas y unitarias, podemos pasar la gramática a Forma Normal de Chomsky. Recordar que una gramática independiente del contexto está en forma Normal de Chomsky si todas las producciones son de la forma $A \\rightarrow BC$ o $A \\rightarrow a$, donde $B$ y $C$ son variables y $a$ es un símbolo terminal. El método transformChomsky transforma una gramática en forma normal de Chomsky.\n",
    "\n",
    "A continuación mostramos un ejemplo donde se lee una gramática, se tranforma a forma Normal de Chomsky y se vuelve a escribir la gramática en esta forma normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of nullable variables \n",
      "[]\n",
      "List of derivable pairs \n",
      "[]\n",
      "Adding the variable <Cb>\n",
      "Adding the production \n",
      "Left part: \n",
      "<Cb>\n",
      "Right part: \n",
      "['b']\n",
      "\n",
      "Adding the variable <Ca>\n",
      "Adding the production \n",
      "Left part: \n",
      "<Ca>\n",
      "Right part: \n",
      "['a']\n",
      "\n",
      "Adding the variable <D1>\n",
      "Adding the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['<Cb>', '<D1>']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "<D1>\n",
      "Right part: \n",
      "['A', 'A']\n",
      "\n",
      "Removing the production \n",
      "Left part: \n",
      "A\n",
      "Right part: \n",
      "['<Cb>', 'A', 'A']\n",
      "\n",
      "Adding the variable <D2>\n",
      "Adding the production \n",
      "Left part: \n",
      "B\n",
      "Right part: \n",
      "['<Ca>', '<D2>']\n",
      "\n",
      "Adding the production \n",
      "Left part: \n",
      "<D2>\n",
      "Right part: \n",
      "['B', 'B']\n",
      "\n",
      "Removing the production \n",
      "Left part: \n",
      "B\n",
      "Right part: \n",
      "['<Ca>', 'B', 'B']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_Chomsky = \"grammar_Chomsky.txt\"\n",
    "grammar_Chomsky = GenerativeGrammar.readGrammar(path_Chomsky)\n",
    "grammar_Chomsky.transformChomsky(True)\n",
    "\n",
    "path_write_Chomsky = \"grammar_written_Chomsky.txt\"\n",
    "grammar_Chomsky.writeGrammar(path_write_Chomsky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma Normal de Greibach\n",
    "\n",
    "\n",
    "Para poder pasar una gramática a Formal Normal de Greibach todas las producciones han de ser de la forma $A \\rightarrow a$ o $A \\rightarrow \\alpha$, donde $\\alpha \\in V^{*}$. El método greibachAppliable comprueba si una gramática cumple estas condiciones y, por consiguiente, está en condiciones de transformarse a forma Normal de Greibach. La transformación de una gramática a forma normal de Greibach puede hacerse mediante el método transformGreibach.\n",
    "\n",
    "En el siguiente ejemplo leemos una gramática desde un fichero, comprobamos si está en condiciones de ser transformada a Forma Normal de Greibach, la transformamos a dicha forma normal. Finalmente, escribimos la gramática en Forma Normal de Greibach en un fichero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path_Greibach = \"grammar_Greibach.txt\"\n",
    "grammar_Greibach = GenerativeGrammar.readGrammar(path_Greibach)\n",
    "\n",
    "greibach_appliable = grammar_Greibach.greibachAppliable(True)\n",
    "print(greibach_appliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the first part of the Greibach algorithm\n",
      "Making the first deletion of the Greibach algorithm with the production \n",
      "Left part: \n",
      "<A3>\n",
      "Right part: \n",
      "['<A2>', '<A3>', '<A2>']\n",
      "\n",
      "Making the second deletion of the Greibach algorithm with the variable <A3>\n",
      "Running the second part of the Greibach algorithm\n",
      "Making the first deletion of the Greibach algorithm with the production \n",
      "Left part: \n",
      "<A2>\n",
      "Right part: \n",
      "['<A3>', '<A1>']\n",
      "\n",
      "Making the first deletion of the Greibach algorithm with the production \n",
      "Left part: \n",
      "<A1>\n",
      "Right part: \n",
      "['<A2>', '<A3>']\n",
      "\n",
      "Making the first deletion of the Greibach algorithm with the production\n",
      "Left part: \n",
      "<B<A3>>\n",
      "Right part: \n",
      "['<A1>', '<A3>', '<A2>']\n",
      "\n",
      "Making the first deletion of the Greibach algorithm with the production\n",
      "Left part: \n",
      "<B<A3>>\n",
      "Right part: \n",
      "['<A1>', '<A3>', '<A2>', '<B<A3>>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar_Greibach.transformGreibach(True)\n",
    "\n",
    "path_write_Greibach = \"grammar_written_Greibach.txt\"\n",
    "grammar_Greibach.writeGrammar(path_write_Greibach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema de la pertenencia con gramáticas en forma Normal de Greibach\n",
    "\n",
    "Como sabemos, la forma Normal de Greibach sirve para poder determinar si una palabra puede ser generada por la gramática con un árbol con una profundidad máxima igual a la longitud de la palabra. En cada nivel del árbol e genera un símbolo terminal. El método checkBelongingRecursiveGreibach sirve para realizar esta búsqueda recursiva en forma normal de Greibach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the first part of the Greibach algorithm\n",
      "Running the second part of the Greibach algorithm\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "word1 = \"ba\"\n",
    "belonging_word1 = grammar_Greibach.wordBelongsGreibach(word1, True)\n",
    "print(belonging_word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con Gramáticas independientes del contexto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya sabemos que la clase de los lenguajes independientes del contexto es cerrada para la unión, concatenación y clausura. Y esto puede verse mediante las correspondientes gramáticas independientes del contexto. \n",
    "\n",
    "Supongamos que tenemos dos gramáticas independientes del contexto $G_1 = (V_1,T,P_1,S_1)$, $G_2 = (V_2,T,P_2,S_2)$. Leemos desde fichero las gramáticas $G_1$ y $G_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"grammar_operations1.txt\"\n",
    "path2 = \"grammar_operations2.txt\"\n",
    "\n",
    "grammar_operations1 = GenerativeGrammar.readGrammar(path1)\n",
    "grammar_operations2 = GenerativeGrammar.readGrammar(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unión de gramáticas independientes del contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La gramática independiente del contexto que genera la unión de los lenguajes generados por las gramáticas $G_1$ y $G_2$ viene determinada por: $(V,T,P,S)$, donde $S$ es una nueva variable, $V = V_1 \\cup V_2 \\cup \\{S\\}$, y $P = P_1 \\cup P_2 \\cup \\{S \\rightarrow S_1, S \\rightarrow S_2 \\}$. El método unionGrammar permite hacer la unión de una gramática independiente del contexto con otra pasada como parámetro. \n",
    " \n",
    " A continuación hacemos la unión de las dos gramáticas anteriores y escribimos en un fichero el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_union = grammar_operations1.unionGrammar(grammar_operations2)\n",
    "out_file_union = \"grammar_union_written.txt\"\n",
    "grammar_union.writeGrammar(out_file_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación de gramáticas independientes del contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gramática independiente del contexto que genera la concatenación de los lenguajes generados por las gramáticas $G_1$ y $G_2$ viene determinada por: $(V,T,P,S)$, donde $S$ es una nueva variable, $V = V_1 \\cup V_2 \\cup \\{S\\}$, y $P = P_1 \\cup P_2 \\cup \\{S \\rightarrow S_1S_2 \\}$. El método concatenationGrammar permite hacer la unión de una gramática independiente del contexto con otra pasada como parámetro. \n",
    "\n",
    "Hacemos la concatenación de las dos gramáticas anteriores y escribimos en un fichero el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_concatenation = grammar_operations1.concatenationGrammar(grammar_operations2)\n",
    "out_file_concatenation = \"grammar_concatenation_written.txt\"\n",
    "grammar_concatenation.writeGrammar(out_file_concatenation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clausura de gramáticas independientes del contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gramática independiente del contexto que genera la clausura del lenguaje generado por las gramática $G_1$ viene determinada por: $(V,T,P,S)$, donde $S$ es una nueva variable, $V = V_1 \\cup \\{S\\}$, y $P = P_1 \\cup \\{S \\rightarrow S_1, S \\rightarrow \\epsilon\\}$. El método clausureGrammar permite hacer la clausura de una gramática independiente del contexto.\n",
    "\n",
    "Hacemos la clausura de $G_1$ y escribimos el resultado en un fichero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_clausure = grammar_operations1.clausureGrammar()\n",
    "out_file_clausure = \"grammar_clausure_written.txt\"\n",
    "grammar_clausure.writeGrammar(out_file_clausure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos para gramáticas independientes del contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenguaje vacío\n",
    "\n",
    "El lenguaje generado por una gramática es vacío sí, y sólo sí, el símbolo inicial no puede sustituirse por una cadena de símbolos terminales. El método emptyLanguaje permite comprobar si el lenguaje generado por una gramática es vacío.\n",
    "\n",
    "A continuación leemos una gramática desde fichero y comprobamos si el lenguaje generado por la misma es vacío. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path_empty = \"grammar_empty.txt\"\n",
    "grammar_empty = GenerativeGrammar.readGrammar(path_empty) \n",
    "\n",
    "empty_languaje = grammar_empty.emptyLanguaje()\n",
    "print(empty_languaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenguaje infinito\n",
    "\n",
    "El método infinityLanguaje permite comprobar si el lenguaje generado por una gramática es infinito. \n",
    "\n",
    "Leemos una gramática desde fichero y comprobamos si el lenguaje generado por ella es finito o infinitos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "path_infinity1 = \"grammar_infinity1.txt\"\n",
    "grammar_infinity1 = GenerativeGrammar.readGrammar(path_infinity1) \n",
    "\n",
    "languaje_infinity1 = grammar_infinity1.infinityLanguaje()\n",
    "print(languaje_infinity1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que si a la gramática anterior le añadimos la producción $C \\rightarrow AB$ el lenguaje generado pasa a ser infinito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path_infinity2 = \"grammar_infinity2.txt\"\n",
    "grammar_infinity2 = GenerativeGrammar.readGrammar(path_infinity2) \n",
    "\n",
    "languaje_infinity2 = grammar_infinity2.infinityLanguaje()\n",
    "print(languaje_infinity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de pertenencia\n",
    "\n",
    "Un problema muy común en gramáticas independientes del contexto es el **problema de pertenencia**. Este problema consiste en, dada una gramática independiente del contexto y una palabra, determinar si la palabra puede ser generada por la gramática. \n",
    "\n",
    "Hemos visto un algoritmo para resolver este problema para gramáticas en Forma Normal de Greibach. Dicho algoritmo es un algoritmo de búsqueda en el espacio de las posibles derivaciones.\n",
    "\n",
    "Existen dos algoritmos más sofisticados:\n",
    "\n",
    "- El algoritmo de **Cocke-Younger-Kasami**, que sólo sirve para gramáticas en Forma Normal de Chomsky.\n",
    "\n",
    "- El algoritmo de **Early**, que sirve para cualquier gramática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Cocke-Younger-Kasami\n",
    "\n",
    "El método checkBelongingCYK permite comprobar si una palabra puede ser generada por la gramática empleando el algoritmo de Cocke-Younger-Kasami. \n",
    "\n",
    "A continuación leemos una gramática desde fichero y comprobamos si las palabras baaba y aaaaa puede ser generadas por la gramática usando este método. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_belonging = \"grammar_belonging.txt\"\n",
    "grammar_belonging = GenerativeGrammar.readGrammar(path_belonging) \n",
    "\n",
    "word1 = \"baaba\"\n",
    "word2 = \"aaaaa\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining V_01\n",
      "AddingBto V_01\n",
      "Determining V_11\n",
      "AddingAto V_11\n",
      "AddingCto V_11\n",
      "Determining V_21\n",
      "AddingAto V_21\n",
      "AddingCto V_21\n",
      "Determining V_31\n",
      "AddingBto V_31\n",
      "Determining V_41\n",
      "AddingAto V_41\n",
      "AddingCto V_41\n",
      "Determining V_02\n",
      "Adding S to V_02\n",
      "Adding A to V_02\n",
      "Determining V_12\n",
      "Adding B to V_12\n",
      "Determining V_22\n",
      "Adding S to V_22\n",
      "Adding C to V_22\n",
      "Determining V_32\n",
      "Adding S to V_32\n",
      "Adding A to V_32\n",
      "Determining V_03\n",
      "Determining V_13\n",
      "Adding B to V_13\n",
      "Determining V_23\n",
      "Adding B to V_23\n",
      "Determining V_04\n",
      "Determining V_14\n",
      "Adding S to V_14\n",
      "Adding C to V_14\n",
      "Adding A to V_14\n",
      "Determining V_05\n",
      "Adding S to V_05\n",
      "Adding A to V_05\n",
      "Adding C to V_05\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "belonging_word1_CYK = grammar_belonging.checkBelongingCYK(word1, True)\n",
    "\n",
    "print(belonging_word1_CYK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining V_01\n",
      "AddingAto V_01\n",
      "AddingCto V_01\n",
      "Determining V_11\n",
      "AddingAto V_11\n",
      "AddingCto V_11\n",
      "Determining V_21\n",
      "AddingAto V_21\n",
      "AddingCto V_21\n",
      "Determining V_31\n",
      "AddingAto V_31\n",
      "AddingCto V_31\n",
      "Determining V_41\n",
      "AddingAto V_41\n",
      "AddingCto V_41\n",
      "Determining V_02\n",
      "Adding B to V_02\n",
      "Determining V_12\n",
      "Adding B to V_12\n",
      "Determining V_22\n",
      "Adding B to V_22\n",
      "Determining V_32\n",
      "Adding B to V_32\n",
      "Determining V_03\n",
      "Adding S to V_03\n",
      "Adding C to V_03\n",
      "Adding A to V_03\n",
      "Determining V_13\n",
      "Adding S to V_13\n",
      "Adding C to V_13\n",
      "Adding A to V_13\n",
      "Determining V_23\n",
      "Adding S to V_23\n",
      "Adding C to V_23\n",
      "Adding A to V_23\n",
      "Determining V_04\n",
      "Adding B to V_04\n",
      "Determining V_14\n",
      "Adding B to V_14\n",
      "Determining V_05\n",
      "Adding S to V_05\n",
      "Adding C to V_05\n",
      "Adding A to V_05\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "belonging_word2_CYK = grammar_belonging.checkBelongingCYK(word2, True)\n",
    "\n",
    "print(belonging_word2_CYK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Early\n",
    "\n",
    "La pertenencia de una palabra al lenguaje generado por una gramática mediante el algoritmo de Early puede comprobarse mediante el método checkBelongingEarly. \n",
    "\n",
    "Comprobamos la pertenencia de la palabras baa al lenguaje generado por la gramática anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining REGISTERS [0] \n",
      "Adding \n",
      "(0, 0, 'S', '', ['A', 'B'])\n",
      "Adding \n",
      "(0, 0, 'S', '', ['B', 'C'])\n",
      "Clausure\n",
      "Adding \n",
      "(0, 0, 'A', '', ['B', 'A'])\n",
      "Adding \n",
      "(0, 0, 'A', '', ['a'])\n",
      "Adding \n",
      "(0, 0, 'B', '', ['C', 'C'])\n",
      "Adding \n",
      "(0, 0, 'B', '', ['b'])\n",
      "Adding \n",
      "(0, 0, 'C', '', ['A', 'B'])\n",
      "Adding \n",
      "(0, 0, 'C', '', ['a'])\n",
      "Advance\n",
      "Adding \n",
      "(0, 1, 'B', 'b', [])\n",
      "Termination\n",
      "Adding \n",
      "(0, 1, 'S', 'B', ['C'])\n",
      "Adding \n",
      "(0, 1, 'A', 'B', ['A'])\n",
      "Clausure\n",
      "Adding \n",
      "(1, 1, 'C', '', ['A', 'B'])\n",
      "Adding \n",
      "(1, 1, 'C', '', ['a'])\n",
      "Adding \n",
      "(1, 1, 'A', '', ['B', 'A'])\n",
      "Adding \n",
      "(1, 1, 'A', '', ['a'])\n",
      "Adding \n",
      "(1, 1, 'B', '', ['C', 'C'])\n",
      "Adding \n",
      "(1, 1, 'B', '', ['b'])\n",
      "Advance\n",
      "Adding \n",
      "(1, 2, 'C', 'a', [])\n",
      "Adding \n",
      "(1, 2, 'A', 'a', [])\n",
      "Termination\n",
      "Adding \n",
      "(0, 2, 'S', 'BC', [])\n",
      "Adding \n",
      "(1, 2, 'B', 'C', ['C'])\n",
      "Adding \n",
      "(0, 2, 'A', 'BA', [])\n",
      "Adding \n",
      "(1, 2, 'C', 'A', ['B'])\n",
      "Adding \n",
      "(0, 2, 'S', 'A', ['B'])\n",
      "Adding \n",
      "(0, 2, 'C', 'A', ['B'])\n",
      "Clausure\n",
      "Adding \n",
      "(2, 2, 'C', '', ['A', 'B'])\n",
      "Adding \n",
      "(2, 2, 'C', '', ['a'])\n",
      "Adding \n",
      "(2, 2, 'B', '', ['C', 'C'])\n",
      "Adding \n",
      "(2, 2, 'B', '', ['b'])\n",
      "Adding \n",
      "(2, 2, 'A', '', ['B', 'A'])\n",
      "Adding \n",
      "(2, 2, 'A', '', ['a'])\n",
      "Advance\n",
      "Adding \n",
      "(2, 3, 'C', 'a', [])\n",
      "Adding \n",
      "(2, 3, 'A', 'a', [])\n",
      "Termination\n",
      "Adding \n",
      "(1, 3, 'B', 'CC', [])\n",
      "Adding \n",
      "(2, 3, 'B', 'C', ['C'])\n",
      "Adding \n",
      "(2, 3, 'C', 'A', ['B'])\n",
      "Adding \n",
      "(1, 3, 'A', 'B', ['A'])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "word = \"baa\"\n",
    "\n",
    "belonging_word_Early = grammar_belonging.checkBelongingEarly(word, True)\n",
    "\n",
    "print(belonging_word_Early)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se considera la gramática $(\\{S,A,B\\},\\{0,1\\},P,S)$, donde $P$ viene determinado por las siguientes producciones:\n",
    "\n",
    "$S \\rightarrow 0A0 \\mid 1B1, \\quad A \\rightarrow 0A0\\mid 1B1, \\quad B \\rightarrow 1B1 $.\n",
    "\n",
    "Se pide leer la gramática desde un fichero que tendrá el formato espeficiado anteriormente y obtener la palabra $00111100$ mediante sucesivas derivaciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sea la gramática $(\\{S,A\\}, \\{a,b,z\\}, P, S)$, siendo $P$ el siguiente conjunto de producciones:\n",
    "\n",
    "$S \\rightarrow aSA \\mid \\epsilon, \\quad A \\rightarrow bA \\mid z \\mid \\epsilon$\n",
    "\n",
    "a) Leer la gramática desde fichero. \n",
    "\n",
    "b) Demostrar que es ambigua obteniendo dos cadenas de derivación diferentes para una misma palabra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dada la gramática $(\\{S,A,B\\}, \\{a\\}, P, S), donde $P$  es el siguiente conjunto de producciones:\n",
    "\n",
    "$S A \\mid B, \\quad A \\rightarrow aaA \\mid \\epsilon, \\quad B \\rightarrow aaaB \\mid \\epsilon$\n",
    "\n",
    "a) Leer la gramática desde fichero \n",
    "b) Demostrar que es ambigua \n",
    "c) Crear una gramática no ambigua lineal por la izquierda que genera el mismo lenguaje y escribirla en un fichero\n",
    "d) Comprobar que la gramática generada es lineal por la izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Construir una gramática lineal por la izquierda que genera el lenguaje formado pr las subcadenas sobre el alfabeto $\\{0,1}$ que contienen un número impar de 0 y 1. \n",
    "\n",
    "Comprobar que la gramática generada es lineal por la izquierda y escribirla en un fichero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.   Obtener la forma normal de Greibach para la siguiente gramática, leyéndola previamente desde fichero\n",
    "\n",
    "$< \\{ S_1, S_2, S_3 \\}, \\{ a,b,c,d,e \\}, P., S_1 >$\n",
    "donde\n",
    "\n",
    "$ P = \\{ S_1 \\rightarrow S_1 S_2 c, S_3, S_3 b S_3; S_2 \\rightarrow S_1 S_1, d; S_3 \\rightarrow S_2 e \\}$.\n",
    "\n",
    "Escribir la gramática resultante en un fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Pasar a forma normal de Greibach la gramática (leyéndola previamente desde fichero)\n",
    "\n",
    " \\begin{array}{ll}\n",
    "  S\\rightarrow AAA, & S \\rightarrow B \\\\\n",
    "   A\\rightarrow aA, & A \\rightarrow B \\\\\n",
    "   B \\rightarrow \\epsilon &  \\\\\n",
    "\\end{array}\n",
    "\n",
    "Escribir en un fichero la gramática resultante. Usando la forma normal obtenida, comprobar si las palabras a y aaaaaa pueden ser generadas por la gramática. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Considerar la gramática independiente del contexto dada por las siguientes producciones:\n",
    "\n",
    "$ S \\rightarrow aABb \\mid aBA \\mid \\epsilon$\n",
    "\n",
    "$ A \\rightarrow aS \\mid bAAA$\n",
    "\n",
    "$ B \\rightarrow aABB \\mid aBAB \\mid aBBA \\mid bS$\n",
    "\n",
    "Leerla desde fichero y determinar si las cadenas $aabaab$ y las cadenas $bbaaa$ son generadas por esta gramática:\n",
    "\n",
    "a) Pasándola a forma normal de Greibach\n",
    "\n",
    "b) Mediante el algoritmo de Cocke-Younger-Kasami. Recordar que para poder aplicar este algoritmo la gramática ha de estar en forma Normal de Greibach. \n",
    "\n",
    "c) Con el algoritmo de Early. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Se considera la siguiente gramática $(V,T,P,S)$, donde V = $\\{S,A,B,C,D,E\\}, \\quad T = \\{a,b,c,d\\}$ y $P$ viene determinado por las siguientes producciones:\n",
    "\n",
    "$S \\rightarrow AB \\mid C \\mid BE, \\quad A \\rightarrow aAb \\mid \\epsilon, \\quad B \\rightarrow cBd \\mid \\epsilon, \\quad C \\rightarrow aCd \\mid aDd, \\quad D \\rightarrow bDc \\mid \\epsilon$.\n",
    "\n",
    "Se pide:\n",
    "\n",
    "a) Leerla desde fichero\n",
    "\n",
    "b) Eliminar símbolos y producciones inútiles.\n",
    "\n",
    "c) Eliminar producciones nulas y unitarias. \n",
    "\n",
    "d) Pasar la gramática a Forma Normal de Chomsky.\n",
    "\n",
    "e) Comprobar mediante al algoritmo de Cocke-Youger-Kasami la pertenencia de las palabras aabbcd y abbccd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Encuentra una gramática libre de contexto en forma normal de Chomsky que genere el lenguaje formado por las cadenas $ucv$ con $u,v \\in \\{0,1\\}^+$ y tales que el nº de subcadenas $01$ en  $u$ es igual al nº de subcadenas $10$ \\en v. \n",
    "\n",
    "Comprueba con el algoritmo CYK si la cadena $010c101$ pertenece al lenguaje generado por la gramática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Crear ejemplos de gramáticas en los que\n",
    "\n",
    "a) El lenguaje generado sea vacío.\n",
    "\n",
    "b) El lenguaje generado sea finito\n",
    "\n",
    "c) El lenguaje generado sea inifinito.\n",
    "\n",
    "Escribir las gramáticas generadas en ficheros separados y comprobar con los métodos correspondientes que cumplen con las condiciones que se piden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Se considera el lenguaje $L = \\{uu^{-1} \\mid u \\in \\{a,b,c\\}^*\\}$. Se pide:\n",
    "\n",
    "a) Crear una gramática independiente del contexto $G$ que genere $L$.\n",
    "\n",
    "b) Crear una gramática $G^{*}$ que genere $L^*$ y almacenarla en un fichero\n",
    "\n",
    "c) Comprobar mediante el algoritmo de Early si las palabras $aaccbbbbccaacbaabc$ y $aaacccbbbbbccaa$ pertenecen al lenguaje que genera $G^{*}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Consideramos los siguientes lenguajes sobre el alfabeto $\\{0,1\\}:\n",
    "\n",
    "$L_1 = \\{0^i1^i, \\quad i \\geq 1\\}$\n",
    "\n",
    "$L_2 = \\{1^j0^j, \\quad j \\geq 1\\}$\n",
    "\n",
    "Se pide:\n",
    "\n",
    "a) Crear gramáticas $G_1$ y $G_2$ para cada uno de estos dos lenguajes. \n",
    "b) Crear gramáticas para la unión y la concatenación de estos lenguajes.\n",
    "c) Comprobar mediante el algoritmo de Early la pertenencia de las palarbas 00111100 y 000011111 a los lenguajes unión y concatenación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
